{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for input video - left leg 90 right leg straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1  \n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread(r'dataset/amit_v1_reference.jpg')\n",
    "threshold = 0.08\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/vtest1.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "# input_video = cv2.VideoCapture(0)\n",
    "input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNot90\": \"Partially Correct\",\n",
    "    \"LegsWrong\": \"Incorrect\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\",\n",
    "    \"ShoulderWrong\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_90 = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    shoulder_wrong = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [25, 27, 29, 31]:\n",
    "                leg_not_90 = True\n",
    "            if frame_keypoint_number in [26, 28, 30, 32]:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number == 13 or frame_keypoint_number == 14:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [16, 18, 20, 22] or frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            if frame_keypoint_number in [11] or frame_keypoint_number in [12]:\n",
    "                shoulder_wrong = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if shoulder_wrong:\n",
    "        label = keypoint_labels[\"ShoulderWrong\"]\n",
    "    elif leg_not_90:\n",
    "        if leg_not_straight:\n",
    "            if hands_not_at_90:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"LegsWrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNot90\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNot90\"], keypoint_labels[\"LegNotStraight\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegsWrong\"], keypoint_labels[\"Idle\"], keypoint_labels[\"ShoulderWrong\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with hands threshold - left leg 90 right leg straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 44\n",
      "Correct Frames: 0\n",
      "Partially Correct Frames: 0\n",
      "Incorrect Frames: 44\n",
      "Final Score: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1  \n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread(r'dataset/amit_v_laptop.jpg')\n",
    "threshold = 0.05\n",
    "hands_threshold = 0.1  # New hands threshold\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/vtest1.mp4'\n",
    "input_video = cv2.VideoCapture(0)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNot90\": \"Partially Correct\",\n",
    "    \"LegsWrong\": \"Incorrect\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\",\n",
    "    \"ShoulderWrong\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_90 = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    shoulder_wrong = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "\n",
    "        # Check for hands using the hands_threshold\n",
    "        if frame_keypoint_number in [15, 16, 17, 18, 19, 20, 21, 22]:\n",
    "            distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "            if distance < hands_threshold:\n",
    "                cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "            else:\n",
    "                hands_not_at_90 = True\n",
    "                cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "        else:\n",
    "            # Check for other keypoints using the general threshold\n",
    "            distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "            if distance < threshold:\n",
    "                cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "            else:\n",
    "                if frame_keypoint_number in [25, 27, 29, 31]:\n",
    "                    leg_not_90 = True\n",
    "                if frame_keypoint_number in [26, 28, 30, 32]:\n",
    "                    leg_not_straight = True\n",
    "                if frame_keypoint_number == 13 or frame_keypoint_number == 14:\n",
    "                    hands_not_at_90 = True\n",
    "                # if frame_keypoint_number in [16, 18, 20, 22] or frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                    \n",
    "                if frame_keypoint_number in [11] or frame_keypoint_number in [12]:\n",
    "                    shoulder_wrong = True\n",
    "                cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if shoulder_wrong:\n",
    "        label = keypoint_labels[\"ShoulderWrong\"]\n",
    "    elif leg_not_90:\n",
    "        if leg_not_straight:\n",
    "            if hands_not_at_90:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"LegsWrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNot90\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNot90\"], keypoint_labels[\"LegNotStraight\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegsWrong\"], keypoint_labels[\"Idle\"], keypoint_labels[\"ShoulderWrong\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "live - left leg 90 right leg straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 240\n",
      "Correct Frames: 75\n",
      "Partially Correct Frames: 61\n",
      "Incorrect Frames: 104\n",
      "Final Score: 39.625\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1  \n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread(r'dataset/amit_v_laptop.jpg')\n",
    "threshold = 0.05\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/vtest1.mp4'\n",
    "input_video = cv2.VideoCapture(0)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNot90\": \"Partially Correct\",\n",
    "    \"LegsWrong\": \"Incorrect\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\",\n",
    "    \"ShoulderWrong\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_90 = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    shoulder_wrong = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [25, 27, 29, 31]:\n",
    "                leg_not_90 = True\n",
    "            if frame_keypoint_number in [26, 28, 30, 32]:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number == 13 or frame_keypoint_number == 14:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [16, 18, 20, 22] or frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            if frame_keypoint_number in [11] or frame_keypoint_number in [12]:\n",
    "                shoulder_wrong = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if shoulder_wrong:\n",
    "        label = keypoint_labels[\"ShoulderWrong\"]\n",
    "    elif leg_not_90:\n",
    "        if leg_not_straight:\n",
    "            if hands_not_at_90:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"LegsWrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNot90\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNot90\"], keypoint_labels[\"LegNotStraight\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegsWrong\"], keypoint_labels[\"Idle\"], keypoint_labels[\"ShoulderWrong\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "live - right leg 90 left leg straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LegNotAbove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 117\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m keypoint_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerfect\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    116\u001b[0m     correct_frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m [keypoint_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandsNotAtRightPosition\u001b[39m\u001b[38;5;124m\"\u001b[39m], keypoint_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandsNotAt90\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mkeypoint_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLegNotAbove\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, keypoint_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLegNotStraight\u001b[39m\u001b[38;5;124m\"\u001b[39m]]:\n\u001b[0;32m    118\u001b[0m     partially_correct_frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m [keypoint_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLegsWrong\u001b[39m\u001b[38;5;124m\"\u001b[39m], keypoint_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdle\u001b[39m\u001b[38;5;124m\"\u001b[39m], keypoint_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShoulderWrong\u001b[39m\u001b[38;5;124m\"\u001b[39m]]:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LegNotAbove'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1  \n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread(r'dataset/amit_v_laptop.jpg')\n",
    "threshold = 0.05\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/vtest1.mp4'\n",
    "input_video = cv2.VideoCapture(0)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNot90\": \"Partially Correct\",\n",
    "    \"LegsWrong\": \"Incorrect\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\",\n",
    "    \"ShoulderWrong\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_90 = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    shoulder_wrong = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [26, 28, 30, 32]:\n",
    "                leg_not_90 = True\n",
    "            if frame_keypoint_number in [25, 27, 29, 31]:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number == 13 or frame_keypoint_number == 14:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [16, 18, 20, 22] or frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            if frame_keypoint_number in [11] or frame_keypoint_number in [12]:\n",
    "                shoulder_wrong = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if shoulder_wrong:\n",
    "        label = keypoint_labels[\"ShoulderWrong\"]\n",
    "    elif leg_not_90:\n",
    "        if leg_not_straight:\n",
    "            if hands_not_at_90:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"LegsWrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNot90\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNot90\"], keypoint_labels[\"LegNotStraight\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegsWrong\"], keypoint_labels[\"Idle\"], keypoint_labels[\"ShoulderWrong\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
