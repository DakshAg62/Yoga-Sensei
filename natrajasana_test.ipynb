{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for input video - left hand & right leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 672\n",
      "Correct Frames: 0\n",
      "Partially Correct Frames: 18\n",
      "Incorrect Frames: 24\n",
      "Final Score: 0.9821428571428568\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "reference_image = cv2.imread(r'dataset/amit_n_reference.jpg')\n",
    "threshold = 0.1\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/ntest.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "# input_video = cv2.VideoCapture(0)\n",
    "input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNotAbove\": \"Partially Correct\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\"\n",
    "}\n",
    "\n",
    "\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = 0\n",
    "score2 = 0\n",
    "score3 = 0\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_above = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    shoulder_wrong = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [26, 28, 30, 32]:\n",
    "                leg_not_above = True\n",
    "            if frame_keypoint_number == 25:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number == 13:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if leg_not_above:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"Idle\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNotAbove\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "\n",
    "    # Check the label and update scores and counts\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        score1 += step\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNotAbove\"]]:\n",
    "        score2 += step / 2\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegNotStraight\"], keypoint_labels[\"Idle\"]]:\n",
    "        score3 += step / 10\n",
    "        incorrect_frames += 1\n",
    "\n",
    "    # ... (Your existing code)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "live - left hand & right leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 164\n",
      "Correct Frames: 59\n",
      "Partially Correct Frames: 53\n",
      "Incorrect Frames: 52\n",
      "Final Score: 48.96341463414634\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1  # Unknown initially\n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread('d:\\One Drive\\OneDrive\\Pictures\\Camera Roll\\WIN_20231218_17_11_07_Pro.jpg')\n",
    "threshold = 0.1\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/ntest.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "input_video = cv2.VideoCapture(0)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNotAbove\": \"Partially Correct\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\"\n",
    "}\n",
    "\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_above = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    shoulder_wrong = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [26, 28, 30, 32]:\n",
    "                leg_not_above = True\n",
    "            if frame_keypoint_number == 25:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number == 13:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if leg_not_above:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"Idle\"]\n",
    "        else:\n",
    "            if leg_not_straight:\n",
    "                label = keypoint_labels[\"LegNotStraight\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"LegNotAbove\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNotAbove\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegNotStraight\"], keypoint_labels[\"Idle\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    # Set total_frames for live video once it's known\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "live - right hand & left leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 284\n",
      "Correct Frames: 50\n",
      "Partially Correct Frames: 8\n",
      "Incorrect Frames: 226\n",
      "Final Score: 11.056338028169014\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1\n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread('d:\\One Drive\\OneDrive\\Pictures\\Camera Roll\\WIN_20231218_17_11_18_Pro.jpg')\n",
    "threshold = 0.1\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/ntest.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "input_video = cv2.VideoCapture(0)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNotAbove\": \"Partially Correct\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_above = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    shoulder_wrong = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [25, 27, 29, 31]:\n",
    "                leg_not_above = True\n",
    "            if frame_keypoint_number == 26:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number == 14:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [16, 18, 20, 22]:\n",
    "                hands_not_at_right_position = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if leg_not_above:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"Idle\"]\n",
    "        else:\n",
    "            if leg_not_straight:\n",
    "                label = keypoint_labels[\"LegNotStraight\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"LegNotAbove\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNotAbove\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegNotStraight\"], keypoint_labels[\"Idle\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    # Set total_frames for live video once it's known\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advanced for input video - right leg in air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 193\n",
      "Correct Frames: 50\n",
      "Partially Correct Frames: 65\n",
      "Incorrect Frames: 78\n",
      "Final Score: 48.80829015544041\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1  \n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread('d:\\One Drive\\OneDrive\\Pictures\\Camera Roll\\WIN_20231218_17_11_37_Pro.jpg')\n",
    "threshold = 0.05 #0.13 for antest1\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/antest.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "# input_video = cv2.VideoCapture(0)\n",
    "input_video = cv2.VideoCapture(input_video_path)\n",
    "output_video_path = 'advancedvriksh/natrajadvtest.mp4'  # Choose your desired output file name\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create a VideoWriter object to save the output video.\n",
    "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNotAbove\": \"Partially Correct\",\n",
    "    \"KneeNotAbove\": \"Partially Correct\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\",\n",
    "    \"BothWrong\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_above = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    knee_not_above = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [28, 30, 32]:\n",
    "                leg_not_above = True\n",
    "            if frame_keypoint_number == 26:\n",
    "                knee_not_above = True\n",
    "            if frame_keypoint_number == 25:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number in [13, 14]:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [15, 17, 19, 21, 16, 18, 20, 22]:\n",
    "                hands_not_at_right_position = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if leg_not_above:\n",
    "        if hands_not_at_90:\n",
    "            if knee_not_above:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"BothWrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNotAbove\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif knee_not_above:\n",
    "        label = keypoint_labels[\"KneeNotAbove\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)\n",
    "    output_video.write(frame_copy)\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNotAbove\"], keypoint_labels[\"KneeNotAbove\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegNotStraight\"], keypoint_labels[\"Idle\"], keypoint_labels[\"BothWrong\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/1.25\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advanced live - right leg in air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 45\n",
      "Correct Frames: 0\n",
      "Partially Correct Frames: 0\n",
      "Incorrect Frames: 45\n",
      "Final Score: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1  \n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread('d:\\One Drive\\OneDrive\\Pictures\\Camera Roll\\WIN_20231218_17_11_48_Pro.jpg')\n",
    "threshold = 0.1 \n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/antest.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "input_video = cv2.VideoCapture(0)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "        \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNotAbove\": \"Partially Correct\",\n",
    "    \"KneeNotAbove\": \"Partially Correct\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\",\n",
    "    \"BothWrong\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_above = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    knee_not_above = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [28, 30, 32]:\n",
    "                leg_not_above = True\n",
    "            if frame_keypoint_number == 26:\n",
    "                knee_not_above = True\n",
    "            if frame_keypoint_number == 25:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number in [13, 14]:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [15, 17, 19, 21, 16, 18, 20, 22]:\n",
    "                hands_not_at_right_position = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if leg_not_above:\n",
    "        if hands_not_at_90:\n",
    "            if knee_not_above:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"BothWrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNotAbove\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif knee_not_above:\n",
    "        label = keypoint_labels[\"KneeNotAbove\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNotAbove\"], keypoint_labels[\"KneeNotAbove\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegNotStraight\"], keypoint_labels[\"Idle\"], keypoint_labels[\"BothWrong\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advanced live - left leg in air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 87\n",
      "Correct Frames: 10\n",
      "Partially Correct Frames: 1\n",
      "Incorrect Frames: 76\n",
      "Final Score: 3.333333333333334\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "frame_count = 0\n",
    "total_frames = -1 \n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread('d:\\One Drive\\OneDrive\\Pictures\\Camera Roll\\WIN_20231218_17_11_37_Pro.jpg')\n",
    "threshold = 0.1 \n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/antest.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "input_video = cv2.VideoCapture(0)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Correct\",\n",
    "    \"HandsNotAtRightPosition\": \"Partially Correct\",\n",
    "    \"HandsNotAt90\": \"Partially Correct\",\n",
    "    \"LegNotAbove\": \"Partially Correct\",\n",
    "    \"KneeNotAbove\": \"Partially Correct\",\n",
    "    \"Idle\": \"Incorrect\",\n",
    "    \"LegNotStraight\": \"Incorrect\",\n",
    "    \"BothWrong\": \"Incorrect\"\n",
    "}\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "correct_frames = 0\n",
    "partially_correct_frames = 0\n",
    "incorrect_frames = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_not_above = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    knee_not_above = False\n",
    "    leg_not_straight = False\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [27, 29, 31]:\n",
    "                leg_not_above = True\n",
    "            if frame_keypoint_number == 25:\n",
    "                knee_not_above = True\n",
    "            if frame_keypoint_number == 26:\n",
    "                leg_not_straight = True\n",
    "            if frame_keypoint_number in [13, 14]:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [15, 17, 19, 21, 16, 18, 20, 22]:\n",
    "                hands_not_at_right_position = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if leg_not_above:\n",
    "        if hands_not_at_90:\n",
    "            if knee_not_above:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"BothWrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegNotAbove\"]\n",
    "    elif leg_not_straight:\n",
    "        label = keypoint_labels[\"LegNotStraight\"]\n",
    "    elif knee_not_above:\n",
    "        label = keypoint_labels[\"KneeNotAbove\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        if hands_not_at_90:\n",
    "            label = keypoint_labels[\"HandsNotAt90\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "    if label == keypoint_labels[\"Perfect\"]:\n",
    "        correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"HandsNotAtRightPosition\"], keypoint_labels[\"HandsNotAt90\"], keypoint_labels[\"LegNotAbove\"], keypoint_labels[\"KneeNotAbove\"]]:\n",
    "        partially_correct_frames += 1\n",
    "    elif label in [keypoint_labels[\"LegNotStraight\"], keypoint_labels[\"Idle\"], keypoint_labels[\"BothWrong\"]]:\n",
    "        incorrect_frames += 1\n",
    "    \n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if total_frames == -1:\n",
    "    total_frames = frame_count\n",
    "step = 100 / total_frames\n",
    "\n",
    "score1 = correct_frames*step\n",
    "score2 = partially_correct_frames*step/2\n",
    "score3 = incorrect_frames*step/10\n",
    "final_score = max(0, score1 + score2 - score3)\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Correct Frames: {correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {incorrect_frames}\")\n",
    "print(f\"Final Score: {final_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
